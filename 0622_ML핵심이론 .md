# ML 핵심이론  Review  - AI



* **AutoML Tables**로 높은 수준의 비즈니스 문제 해결하기 @ http://j.mp/2KjsNOP & https://j.mp/2UT3bMf

[9:33](https://w1647847118-lq5111919.slack.com/archives/C03KK7CFU4C/p1655857993228229)

- ML models without a single line of code : **Peltarion** @ [https://peltarion.com](https://peltarion.com/) + **Clarifai** @ https://j.mp/3vqOAtA + **RunwayML** @ [https://runwayml.com](https://runwayml.com/) & http://j.mp/2QeNmPg

- An Interactive Introduction to Fourier Transforms @ https://j.mp/2J0yv9A

* 딥러닝으로 오디오 만나보기 (Fourier Transform & MFCC) @ http://j.mp/2XJa1Yo

-  머신러닝 용어집 (Google ML Crash course) @ **https://goo.gl/Q4bYbz**
- 학습률 테스트 @ https://goo.gl/yvhwnu
- 딥러닝에서 클래스 불균형을 다루는 방법 (Weight balancing & Focal loss / Over & under sampling / SMOTE) @ http://j.mp/2qrkTuM & https://j.mp/3kR6Sxl





Data -> 정형데이터로 정제한다 -> count vectorizer

ex)

-  count vectorizer : 

>  [정부, 코로나 , 인공지능, 영화] - 매일(출현횟수){**중요도 떨어뜨리기**}  주제(카테고리)
>
> ​	2		1			0		0			52													1

​	

- **TF-IDF vectorizer** : 중요도 떨어뜨리기

![image-20220622094740108](/Users/krc/Library/Application Support/typora-user-images/image-20220622094740108.png)



#### 데이터를 가장 잘 설명하는 모델을 어떻게 찾을 것인가

- **model's capacity**(포용력) [많다고 좋은게 아니다]
- Model complexity (차원수 등등) 

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622095229037.png" alt="image-20220622095229037" style="zoom:50%;" />

- 과적합 발생-> **Generalization error 증가**

  > 새로운 데이터들에 대해
  >
  > trianing data를 많이 확보(+ data augmentation & Test time augmentation)



## 선형회귀

종속변수 y 와 한개 이상의 독립변수 x 사이의 선형 상관관계를 모델링하는 회귀분석 기법

> 
>
>  y= ax+b

a : **가중치**를 얼마나 곱할지

b:(**bias**: 편향) **보정치**

 세타: 가중치

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622101859139.png" alt="image-20220622101859139" style="zoom:50%;" />



#### 선형결합 Linear Combination 

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622101923128.png" alt="image-20220622101923128" style="zoom:50%;" />



#### 비용함수 Cost fuction 

![image-20220622102217903](/Users/krc/Library/Application Support/typora-user-images/image-20220622102217903.png)





#### Gradient Descent Algorithm 경사하강법

- Gradient == 기울기

- 모든 변수의 편미분을 벡터로 정리한것

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622103812774.png" alt="image-20220622103812774" style="zoom:50%;" />

> New theta= old theta [- alpha  (델타:기울기)  J theta] => **새로운값 = 기존값 * 기울기**
>
> > J theta: cost function => MSE
> >
> > 

- alpha = learning rate 학습률 (=보폭) ==> Hyper parameter 의 중 하나이다 (사람이 결정해줌)

  > 보통 0.01 , 0.001 사용 

- Model Tuning => Hyper parameter =>Hyper parameter optimization => HPO -> AutoML(Auto FE/AutoMS/AutoHPO) 중 하나임 



> 집 추세를 알아볼것
>
> 집 크기 :x
>
> 집 가격 : y
>
> 에러 각각 구함



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622102538697.png" alt="image-20220622102538697" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622102600999.png" alt="image-20220622102600999" style="zoom:50%;" />

> 이때 2번 과정 생략
>
> 세타1을 2로 고정 
>
> 세타0 을 3으로 고정

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622102751679.png" alt="image-20220622102751679" style="zoom:50%;" />

> 세타1 을 2.5고정 하며 점점 갑을 다르게해 MSE 값을 계산
>
> > 다 계산하기 힘듦으로 graident distance 계산법 사용
>
> y=2x+3 	
>
> 한 점을 찍고 미분을 하면 기울기 값을 얻을수 있다.
>
> 기울기 부호찾고, 기울기부호 반대방향으로 이동반복

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622103222788.png" alt="image-20220622103222788" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622103244422.png" alt="image-20220622103244422" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622103319854.png" alt="image-20220622103319854" style="zoom:50%;" />

> 가장 낮은 값을 찾아낼수있다.
>
> Global Minimum





> 알파를 1로 생각하고 계산

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622104039377.png" alt="image-20220622104039377" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622104129922.png" alt="image-20220622104129922" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622104204241.png" alt="image-20220622104204241" style="zoom:50%;" />



### Logistic Reression 로지스틱 회귀

: 이진분류 binary classification 문제를 해결하기 위한모델

하나의 행에대한 확률값 => y 

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622111557529.png" alt="image-20220622111557529" style="zoom:50%;" />

- **Sigmoid function** 

  : <img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622111748578.png" alt="image-20220622111748578" style="zoom:50%;" />

  > MSE 사용하면 빠져나오기 힘든 커브처럼 보임=> **Cross- entropy function** 사용

  <img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622111513613.png" alt="image-20220622111513613" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622111423578.png" alt="image-20220622111423578" style="zoom:50%;" />

> 0.5 : cut off

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622111644842.png" alt="image-20220622111644842" style="zoom:50%;" />

세타1 :기울기

세타0 : x축 이동

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622111710157.png" alt="image-20220622111710157" style="zoom:50%;" />

- **Cross- entropy function**

  

  <img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622112046000.png" alt="image-20220622112046000" style="zoom:50%;" />

Original taget 					**integer**

 ==> #  of classes =3										

Others: class 0				[1,0,0]    (1=100% , 0= 0%)		==> **one hot label**

Repub: class 1				 [0,1,0]

Democr:class 2				[0,0,1]

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622112853957.png" alt="image-20220622112853957" style="zoom:50%;" />



> 인공신경망중 classification 사용
>
> 하나의 행을 세운다 
>
> 합쳤을때 1이 되도록 만들어줌 : soft max function

![image-20220622112840334](/Users/krc/Library/Application Support/typora-user-images/image-20220622112840334.png)

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622112920122.png" alt="image-20220622112920122" style="zoom:50%;" />

> 클래스가 속할 확률

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622113042899.png" alt="image-20220622113042899" style="zoom:50%;" />

> 두 분포의 거리 : cross- entropy



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622113212568.png" alt="image-20220622113212568" style="zoom:50%;" />

> Model 1 
>
> 40% 확률로 demo
>
> 결과: 맞췄다



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622113421442.png" alt="image-20220622113421442" style="zoom:50%;" />

> Cross entropy : 낮을수록 좋은 평가

>모델1 은 아슬아슬하게 맞추고, 확실하게 틀림
>
>모델2는 확실하게 맞추고 , 아쉽게 틀림
>
>모델2가 더 우수함





### softmax Algorithm

: 다중분류 클래스 분류 문제를 위한 알고리즘

>  소프트맥스하고 크로스엔트로피 하는 흐름기억



- SVM 서포트 벡터 머신

​	:

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622113944659.png" alt="image-20220622113944659" style="zoom:50%;" />



> B1 : decision boundary



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622114044480.png" alt="image-20220622114044480" style="zoom:50%;" />

> 두직선사이의 거리 계산

> SVM :margin 을 최대화하눈 결정 경계(면)을 찾는 기법



#### soft-Margin SVM

:SVM :margin 을 최대화하눈 결정 경계(면)을 찾는 기법



Objective function :크게도 작게도 해서 문제를 풀게할수있다. 최소화하면 ->cost function 과 비슷하다



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622114348440.png" alt="image-20220622114348440" style="zoom:50%;" />

> 중괄호 안 값을 최소화하는 것이 목적
>
>  { MSE (cost function 같은것) }
>
> 

> MAX  2/w : 마진을 최대화   => MIN w/2 최소화



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622132537010.png" alt="image-20220622132537010" style="zoom:50%;" />



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622114831181.png" alt="image-20220622114831181" style="zoom:50%;" />

> 크사이 다 더해서 10 이라 가정

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622114908902.png" alt="image-20220622114908902" style="zoom:50%;" />

> 
>
> C 를 0.01 로 정해줌
>
> C를 크게줄수록 오버피팅 증가



#### KSVM 커널 서포트 벡터 머신

데이터가 **선형적으로 분리되지 않을 경우** : 선형 분리 불가능 **Linearly Unseparable**

=> 커널사용!

Original data가 놓여있는 차원을 비선형 매핑(**mapping**)을 통해 **고차원공간으로 변환**시키는것으로 해결

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622115524333.png" alt="image-20220622115524333" style="zoom:50%;" />



> 기준되는 면형을 만들수있다.
>
> 문제해결하고 원본 차원으로 다시 돌아옴

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622115716558.png" alt="image-20220622115716558" style="zoom:50%;" />

> 커널함수도 Hyper parameter

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622115749994.png" alt="image-20220622115749994" style="zoom:50%;" />

> 단일행이 10열이 있다고 가정
>
> 열을 90도 눕혀서 하나의 행으로 만든다
>
> 인공신경망 있을때
>
> 1. x(각 행의 숫자)에 세타를 곱해서 모두 합한다. => 하나의 새로운 열을 만든다 => Layer => Learnable Kernel

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622120014005.png" alt="image-20220622120014005" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622120116566.png" alt="image-20220622120116566" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220622120147001.png" alt="image-20220622120147001" style="zoom:50%;" />

