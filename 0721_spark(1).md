0721

# Spark (1)





## 배울내용

![image-20220721134857743](/Users/krc/Library/Application Support/typora-user-images/image-20220721134857743.png)

![image-20220721134905755](/Users/krc/Library/Application Support/typora-user-images/image-20220721134905755.png)

> Sources , Storage, Query : 서비스 레벨 보다는 로우레벨 문제들을 푸는 분야
>
> Ingestion & Transformation  , Processing : 일반적인 엔지니어링 "수집 및 변환 , 데이터 처리"에 집중되어있다.

![image-20220721135415760](/Users/krc/Library/Application Support/typora-user-images/image-20220721135415760.png)

> 배울내용들



## Batch & Stream Processing

### Batch

**많은양의 데이터를 정해진 시간에 한꺼번에 처리하는것**

1. 한정된 대량의 데이터
2. 특정 시간
3. 일괄처리

**언제 사용하는가? (주기적인일)**

1. 실시간 보장하지 않아도 될때
2. 데이터 한꺼번에 처리 할 수 있을때
3. 무거운 처리를 할때 (ex. ML학습)



### Stream Processing

**데이터가 생성되어 요청이 들어올때마다 처리할수있다.**

1. 실시간성을 보장해야될때
2. 데이터가 여러 소스로부터 들어올때 
3. 데이터가 가끔 들어오거나 지속적으로 들어올때
4. 가벼운 처리를 할때 (ex. Rule-based)

> 1. 사기거래탐지 (Fraud Detection)
> 2. 이상탐지 (Anomaly Detection)
> 3. 실시간 알림
> 4. 비즈니스 모니터링
> 5. 실시간 수요공급 측정및 가격책정
> 6. 실시간 기능이 들어가는 어플리케이션



#### Batch vs Stream 

일반적인 배치 처리 플로우 :											<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721140506036.png" alt="image-20220721140506036" style="zoom: 50%;" />

1. 데이터를 모아서
2. 데이터베이스에서 읽어서 처리
3. 다시 데이터베이스에 담기 												





일반적인 스트림 처리 플로우:							 <img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721140731876.png" alt="image-20220721140731876" style="zoom:50%;" />

1. 데이터가 들어올때마다 (ingest)
2. 쿼리/처리 후 Stage를 업데이트
3. DB에 담기



### micro-Batch

마이크로 배치란?

데이터를 **조금씩 잘라서** **프로세싱**하는 방식

Batch 프로세싱을 잘게 쪼개서 스트리밍을 흉내내는 방식

**spark Steaming** 마이크로배치 방식 사용



실 서비스 활용 예시 (머신러닝)

 우버의 **미켈란젤로** 프로젝트

미켈란젤로 프로젝트는 쉽게 머신러닝 알고리즘을 학습하고 배포할 수 있는 플랫폼

배달시간 예측에 사용

온라인/ 오프라인 파트로 나누어 설계되어짐

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721141537748.png" alt="image-20220721141537748" style="zoom: 33%;" />

1. 데이터 관리

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721141607128.png" alt="image-20220721141607128" style="zoom: 50%;" />

2. 학습

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721141744680.png" alt="image-20220721141744680" style="zoom:50%;" />

3. 배포

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721141932048.png" alt="image-20220721141932048" style="zoom:50%;" />

4. 예측

![image-20220721141809417](/Users/krc/Library/Application Support/typora-user-images/image-20220721141809417.png)



실시간 모니터링 대시보드를 만들어 피쳐,  아웃풋, 이상치 파악할 수 있다

![image-20220721142034982](/Users/krc/Library/Application Support/typora-user-images/image-20220721142034982.png)





## Dataflow Orchestration

오케스트레이션이 필요한 이유

1. 서비스가 커지면서 데이터 플랫폼의 복잡도가 커짐
2. 데이터가 사용자와 직접 연관되는 경우가 늘어남 (워크플로우가 망가지면 서비스도 망가짐)
3. 테스크 하나하나가 중요해짐
4. 테스크간 의존성도 생김

대표적인 프로그램 apache airflow

데이터 테스크를 관리해준다.



## 데이터 엔지니어 프로젝트

### 데이터 기반 의사결정 사례 - Uber Michelangelo

앞으로 만들 프로젝트

**배치** 파이프라인과 **스트림** 파이프라인을 동시에 사용하는

**ML데이터 학습+ 서빙 파이프라인** 만들기 (미켈란젤로의 심플한 버젼)



#### 배치 파이프라인

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721144620304.png" alt="image-20220721144620304" style="zoom:50%;" />

> 특히 데이터 프리프로세싱과 ML학습은 주기적으로 실행될것이기때문에 에어플로우 오케스트라로 관리한다



#### 스트림 파이프라인

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721144817502.png" alt="image-20220721144817502" style="zoom:50%;" />



#### 배치+스트림 파이프라인

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721144846927.png" alt="image-20220721144846927" style="zoom:50%;" />





## 기초 환경설정

필요한 환경& 패키지

1. 파이썬
2. 주피터노트북
3. 자바
4. 스파크
5. Pyspark



- Anaconda 설치
- brew로 설치

~~~ python
# brew.sh 홈페이지 brew다운

#brew로 java설치 8버젼은 아래의 명령어 사용해야함
brew install --cask adoptopenjdk8

#에러남
#Error: Cask 'adopeopenjdk8' is unavailable: No Cask with this name exists.

#brew 버전 업그레이드
brew upgrade

# brew cask버전 다운으로 에러 해결
brew tap homebrew/cask-versions

brew install --cask adoptopenjdk8 # 자바설치 완료

#scala 설치
brew install scala

#apache-spark 설치
brew install apache-spark

# 파이썬 버전확인 
pip --version   # python 3.8

# pyspark 설치
pip install pyspark

pyspark # 스파크 접속

exit() #접속 종료

~~~





## 모빌리티 데이터 다운로드

https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page

Taxi&Limousine Commission

#### NewYork TLC Trip Record Data 

1. 10+년 이상의 택시와 모빌리티 서비스 기록 (2009-2021)
2. 매년 20GB씩 쌓이는 dataset (승하차 시간 장소, 소요시간,요금 데이터 포함)
3. 2020년 우버 데이터 사용

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220721161728772.png" alt="image-20220721161728772" style="zoom: 50%;" />