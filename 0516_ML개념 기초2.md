# 머신러닝 개념 기초2



## loss function

파라미터를 가지고 동작하는 머신러닝 (리니어 리그레션 leaner regration, leaner ~ , )

L = loss function (차이)

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516092516466.png" alt="image-20220516092516466" style="zoom:50%;" />



![image-20220516092241639](/Users/krc/Library/Application Support/typora-user-images/image-20220516092241639.png)



![image-20220516092351833](/Users/krc/Library/Application Support/typora-user-images/image-20220516092351833.png)

최소가 되는 지점을 찾을 수있다



![image-20220516092451101](/Users/krc/Library/Application Support/typora-user-images/image-20220516092451101.png)



## loss function optimization 

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516093250033.png" alt="image-20220516093250033" style="zoom:50%;" />

L(w)=w^2 (어쩌구저쩌구의 형태)

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516092916344.png" alt="image-20220516092916344" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516093032752.png" alt="image-20220516093032752" style="zoom:50%;" />

w=1 일때 최소라는뜻

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516093058248.png" alt="image-20220516093058248" style="zoom:50%;" />

w가 무조건 최소가 된다 

Loss 가 최소가 되는 모델을 찾을수 있다.



* **그냥 함수를 미분해서 0이되는 지점을 찾으면 안되나요?**

analytic solution 을 찾기 힘든이유 

1. Feature space가 일반적으로 다차원임 (현실공간에서는 100차원 공간의 최소를 찾아야하므로 어렵다)
2. L(w)가 convex(볼록함수)가 아님 (대부분의 loss function이 볼록함수가 아님 =찾기힘듬)
3. 다차원 공간에서 미분한 결과로 최소를 찾기힘듬 (ex saddle point: 프링글스처럼 다차원공간에서 어느축에서는 2차원(최소), 다른축에서는 다차원(최소)나옴)



### "Gradient Descent Algorithm"

> 산맥의 최저지점으로 도달하라! 지시받고 아무데나 떨어진다
>
> 전체 지도가없다
>
> 최소가 어딘지 알수없다
>
> 서있는지점에서 가파른방향으로 내려가는것으로 최선을다해 내려간다 (기울기)
>
> 더이상 내려갈곳이없으면 최소 도달한다.

![image-20220516094432819](/Users/krc/Library/Application Support/typora-user-images/image-20220516094432819.png)



<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516094340013.png" alt="image-20220516094340013" style="zoom:50%;" />

: 미분하여 gradient vector를 찾을수있다.



![image-20220516094708651](/Users/krc/Library/Application Support/typora-user-images/image-20220516094708651.png)

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516094729766.png" alt="image-20220516094729766" style="zoom:50%;" />

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516094833790.png" alt="image-20220516094833790" style="zoom:50%;" />

w 를 계속 업데이트 한다 <- w - 미분한 w(기울기 구한것) *[hyper parameter]

(내려갈꺼니까 - 를 사용한다 )

<img src="/Users/krc/Library/Application Support/typora-user-images/image-20220516095122530.png" alt="image-20220516095122530" style="zoom:50%;" />

Local optima : 최선의 최소 (무조건적인 최소가아님) 



## ML workflow

![image-20220516102148365](/Users/krc/Library/Application Support/typora-user-images/image-20220516102148365.png)

데이터 정형화 : 테이블을 어떻게 조인할건가 / 어떤 기준으로 할것인가 

데이터 정의 : 타겟벨류 y 정의 / (머신러닝 문제 정의) 지도학습 , 비지도 학습 

평가 :  ml model 을 빠르게 결과를 확인하고 feedback 과정을 여러번 한다 [prototype] 형식으로 한다.

[완벽하게 하려고 하지말고 일단 여러번해라]





